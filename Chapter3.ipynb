{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3b808d71"
   },
   "source": [
    "# Chapter 3: GPU programming.\n",
    "\n",
    "This chapter and the next will make extensive use of GPUs. Sadly, depending on your machine, it can be impossible to use it in python. For example, at the time I do this tutorial, Radeon is not supported. Also some of your laptop may not have GPUs. These reasons pushed me to run the next Chapter on google collab (https://colab.research.google.com/). If you are still interested in using your own GPUs here are some advice/links that might help you:\n",
    "\n",
    "- https://towardsdatascience.com/installing-tensorflow-with-cuda-cudnn-and-gpu-support-on-windows-10-60693e46e781\n",
    "- https://www.youtube.com/watch?v=hHWkvEcDBO0\n",
    "- https://www.youtube.com/watch?v=KZFn0dvPZUQ\n",
    "- https://towardsdatascience.com/installing-tensorflow-gpu-in-ubuntu-20-04-4ee3ca4cb75d\n",
    "- https://medium.com/analytics-vidhya/install-tensorflow-2-for-amd-gpus-87e8d7aeb812\n",
    "\n",
    "Why do we want to use GPUs ?\n",
    "\n",
    "GPUs hardware is designed for data parallelism. Maximum throughput is achieved when you are computing the same operations on many different elements at once.\n",
    "\n",
    "https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html\n",
    "\n",
    "Among the tasks that do significantly benefit from parallel processing is deep learning. Some tasks can't be done in parallel (When you need to have the same object in memory, e.g calculating a series like fibonnaci).\n",
    "\n",
    "One thing that could be nice would be to write the same code as normal (numpy, pandas,..) but just to run computation on a GPU. This would make it easier to parallelize processes. Some companies/university/people are working on this kind of libraries and that's what we are going to use in this section.\n",
    "\n",
    "Structure:\n",
    "- [Collab](#Collab)\n",
    "- [CuPy](#CuPy)\n",
    "- [CuDF and CuML](#CuDF)\n",
    "- [Numba](#Numba)\n",
    "- [TODO](#TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7c08a575"
   },
   "source": [
    "<a name=\"Collab\"></a>\n",
    "## Google Collab\n",
    "\n",
    "Stockage is limited to 60 gb (see on the left) \n",
    "\n",
    "Ram is limited to 12 gb (top right)\n",
    "\n",
    "You can select gpu accelerated from modify->parameter of the notebook. \n",
    "\n",
    "Create text block and code block\n",
    "\n",
    "You can create section.\n",
    "\n",
    "Resembles jupyter notebook and uses ipynb.\n",
    "\n",
    "Change color and shortcut in utils\n",
    "\n",
    "The os you are connected to is ubuntu\n",
    "To run something in the terminal you need to add \"!\" in front of it\n",
    "\n",
    "Python already installed.\n",
    "\n",
    "Session are limited in time.\n",
    "\n",
    "To use GPU go to Execution and modify the type of execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9bf8034b",
    "outputId": "97a8464b-63fc-4dce-d68d-6302006df535"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.12\n"
     ]
    }
   ],
   "source": [
    "# Check Python Version\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7d5f64ea",
    "outputId": "0d925dd3-b567-4c4f-c8f4-fd6fc4abdd21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No LSB modules are available.\n",
      "Distributor ID:\tUbuntu\n",
      "Description:\tUbuntu 18.04.5 LTS\n",
      "Release:\t18.04\n",
      "Codename:\tbionic\n"
     ]
    }
   ],
   "source": [
    "# Check Ubuntu Version\n",
    "!lsb_release -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5cda8787",
    "outputId": "778bddd1-d3ea-4b11-a231-7f25b6b51cbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2020 NVIDIA Corporation\n",
      "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
      "Cuda compilation tools, release 11.1, V11.1.105\n",
      "Build cuda_11.1.TC455_06.29190527_0\n",
      "/usr/local/cuda/bin/nvcc\n"
     ]
    }
   ],
   "source": [
    "# Check CUDA/cuDNN Version\n",
    "!nvcc -V && which nvcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8c2aa124",
    "outputId": "65b0b924-3075-4a8f-c269-edd88d152772"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Sep 21 08:35:45 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   35C    P8    28W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Check GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8a6b913a",
    "outputId": "168cb573-3aab-4387-aab1-e3f54dce23de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processor\t: 0\n",
      "vendor_id\t: GenuineIntel\n",
      "cpu family\t: 6\n",
      "model\t\t: 63\n",
      "model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
      "stepping\t: 0\n",
      "microcode\t: 0x1\n",
      "cpu MHz\t\t: 2299.998\n",
      "cache size\t: 46080 KB\n",
      "physical id\t: 0\n",
      "siblings\t: 2\n",
      "core id\t\t: 0\n",
      "cpu cores\t: 1\n",
      "apicid\t\t: 0\n",
      "initial apicid\t: 0\n",
      "fpu\t\t: yes\n",
      "fpu_exception\t: yes\n",
      "cpuid level\t: 13\n",
      "wp\t\t: yes\n",
      "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n",
      "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n",
      "bogomips\t: 4599.99\n",
      "clflush size\t: 64\n",
      "cache_alignment\t: 64\n",
      "address sizes\t: 46 bits physical, 48 bits virtual\n",
      "power management:\n",
      "\n",
      "processor\t: 1\n",
      "vendor_id\t: GenuineIntel\n",
      "cpu family\t: 6\n",
      "model\t\t: 63\n",
      "model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
      "stepping\t: 0\n",
      "microcode\t: 0x1\n",
      "cpu MHz\t\t: 2299.998\n",
      "cache size\t: 46080 KB\n",
      "physical id\t: 0\n",
      "siblings\t: 2\n",
      "core id\t\t: 0\n",
      "cpu cores\t: 1\n",
      "apicid\t\t: 1\n",
      "initial apicid\t: 1\n",
      "fpu\t\t: yes\n",
      "fpu_exception\t: yes\n",
      "cpuid level\t: 13\n",
      "wp\t\t: yes\n",
      "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n",
      "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n",
      "bogomips\t: 4599.99\n",
      "clflush size\t: 64\n",
      "cache_alignment\t: 64\n",
      "address sizes\t: 46 bits physical, 48 bits virtual\n",
      "power management:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat /proc/cpuinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4de5dbc"
   },
   "source": [
    "<a name=\"CuPy\"></a>\n",
    "## CuPy\n",
    "\n",
    "CuPy is the GPU equivalent to Numpy. CuPy uses the same methods that numpy so cost entry going from Numpy to CuPy is low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ae817d02"
   },
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "12ef583d",
    "outputId": "ca9ef7f8-7d10-4d32-d9de-dcb7173804b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 2.],\n",
       "       [3., 4., 5.]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = cp.arange(6).reshape(2, 3).astype('f')\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f1405d78",
    "outputId": "0118ad9d-9d55-492c-d6f0-30626b3ac18b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.5, 2.5, 3.5], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "04bf1c0e",
    "outputId": "9b433aec-cfac-4692-d2f6-46fa716e2d7c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3., 12.], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ff555e02",
    "outputId": "af2e487e-23f0-4b3f-b6cf-3ed07e5cd9b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5, 14],\n",
       "       [14, 50]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.dot(z.T).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c36bce47",
    "outputId": "121f3768-b64f-42d3-fa73-31a2142469d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n",
      "(2, 5)\n",
      "(40, 8)\n",
      "<CUDA Device 0>\n"
     ]
    }
   ],
   "source": [
    "ary = cp.arange(10).reshape((2,5))\n",
    "print(ary.dtype)\n",
    "print(ary.shape)\n",
    "print(ary.strides)\n",
    "print(ary.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4612e5fb-356a-4cc1-afbc-1e4becbc2906"
   },
   "source": [
    "You can easily convert numpy array to cupy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b027c689",
    "outputId": "c6be332c-a7e2-4902-e784-2ba8a28a8ba5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu: [0 1 2 3 4 5 6 7 8 9]\n",
      "gpu: [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "ary_cpu = np.arange(10)\n",
    "ary_gpu = cp.asarray(ary_cpu)\n",
    "print('cpu:', ary_cpu)\n",
    "print('gpu:', ary_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0c57ccd7",
    "outputId": "d1528377-2d69-40e6-a675-c452d8a3eac3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "ary_cpu_returned = cp.asnumpy(ary_gpu)\n",
    "print(repr(ary_cpu_returned))\n",
    "print(type(ary_cpu_returned))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a519bad1-8e3a-4caf-b118-8adc43cccde1"
   },
   "source": [
    "Ufunc are also available on cupy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c339156a",
    "outputId": "047d93ab-0b59-414b-9f00-6a17f60155bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  2  4  6  8 10 12 14 16 18]\n",
      "[1.00000000e+00 6.06530660e-01 1.35335283e-01 1.11089965e-02\n",
      " 3.35462628e-04 3.72665317e-06 1.52299797e-08 2.28973485e-11\n",
      " 1.26641655e-14 2.57675711e-18]\n",
      "16.881943016134134\n",
      "[ 5.06424225  8.06825008  4.90058205  7.76730818 -0.01053254  6.88729895\n",
      "  3.58324392  7.93736922  6.83135433  4.12706551]\n"
     ]
    }
   ],
   "source": [
    "print(ary_gpu * 2)\n",
    "print(cp.exp(-0.5 * ary_gpu**2))\n",
    "print(cp.linalg.norm(ary_gpu))\n",
    "print(cp.random.normal(loc=5, scale=2.0, size=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5231863f"
   },
   "source": [
    "You may notice a slight pause when you run these functions the first time. This is because CuPy has to compile the CUDA functions on the fly, and then cache them to disk for reuse in the future. Let's compare some performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bb47f263"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cupy as cp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fc706154"
   },
   "source": [
    "Let's compare a simple multiplication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0721c11b",
    "outputId": "1b547f5a-c90f-49e6-aff6-1952624593ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 5: 1.18 s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "# small example taken from here https://giters.com/cupy/cupy/issues/4891?amp=1\n",
    "\n",
    "a_cpu = np.ones((1000, 20000), dtype='float32')\n",
    "b_cpu = np.ones((20000, 2000), dtype='float32')\n",
    "z_cpu = np.matmul(a_cpu, b_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "638d34f8",
    "outputId": "a3c81dd8-05b2-4840-9f7d-e6a392775cc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 1402.62 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1 loop, best of 5: 209 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "# small example taken from here https://giters.com/cupy/cupy/issues/4891?amp=1\n",
    "\n",
    "a_gpu = cp.ones((1000, 20000), dtype='float32')\n",
    "b_gpu = cp.ones((20000, 2000), dtype='float32')\n",
    "z_gpu = cp.matmul(a_gpu, b_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2108e71"
   },
   "source": [
    "Now the analytical solution of OLS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d3e4cee5"
   },
   "outputs": [],
   "source": [
    "X_cpu = np.random.rand(20000, 1000).astype('f')\n",
    "Y_cpu = np.random.rand(20000, 1).astype('f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "91325f73"
   },
   "outputs": [],
   "source": [
    "X_gpu = cp.asarray(X_cpu,dtype='float32')\n",
    "Y_gpu = cp.asarray(Y_cpu,dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "60432f2d",
    "outputId": "f753f0e8-9216-4537-f963-d8f2e9f711a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 5: 476 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "beta = np.matmul(np.linalg.inv(np.matmul(X_cpu.T,X_cpu)),np.matmul(X_cpu.T,Y_cpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e81647e4",
    "outputId": "bf67bab3-7b68-43e4-c387-0a61b42be8ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 80.32 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1 loop, best of 5: 70.6 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "beta = np.matmul(np.linalg.inv(np.matmul(X_gpu.T,X_gpu)),np.matmul(X_gpu.T,Y_gpu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93fafe9f"
   },
   "source": [
    "This does not mean that GPUs are always faster. When are they worst ? \n",
    "Read more here https://towardsdatascience.com/heres-how-to-use-cupy-to-make-numpy-700x-faster-4b920dda1f56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8046ff16"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sample_data/california_housing_train.csv\")\n",
    "intercept = np.ones(len(df))\n",
    "\n",
    "y = np.array(df[\"median_house_value\"],dtype='float32')\n",
    "X = np.array(df.drop([\"median_house_value\"],axis=1),dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9216c7fc"
   },
   "outputs": [],
   "source": [
    "y_gpu = cp.asarray(y,dtype='float32')\n",
    "X_gpu = cp.asarray(X,dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c6b27bb5",
    "outputId": "66321898-d776-4b51-95aa-442699ddc82e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 20.02 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1000 loops, best of 5: 407 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "beta = np.matmul(np.linalg.inv(np.matmul(X.T,X)),np.matmul(X.T,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "abf007f2",
    "outputId": "b333f520-d4b7-4ee4-f80c-559b30291ff7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 5: 818 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "beta = cp.matmul(cp.linalg.inv(cp.matmul(X_gpu.T,X_gpu)),cp.matmul(X_gpu.T,y_gpu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dd188b9c"
   },
   "source": [
    "Also cupy works best when using ufunc but like we have seen in the introduction, not every operation can be done using ufunc. To overcome this issue you can create your own \"Kernel\". (read more here https://docs.cupy.dev/en/stable/user_guide/kernel.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fr8ir8IesyFH"
   },
   "outputs": [],
   "source": [
    "x = cp.arange(10, dtype=np.float32).reshape(2, 5)\n",
    "y = cp.ones(10, dtype=np.float32).reshape(2, 5)\n",
    "\n",
    "\n",
    "squared_diff = cp.ElementwiseKernel(\n",
    "   'float32 x, float32 y',\n",
    "   'float32 z',\n",
    "   'z = (x - y) * (x - y)',\n",
    "   'squared_diff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "21OQrPWQsyPP",
    "outputId": "f9085a7d-12bd-44ac-d455-2a3da1816bed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [[0. 1. 2. 3. 4.]\n",
      " [5. 6. 7. 8. 9.]]\n",
      "y: [[1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]]\n",
      "result : [[ 1.  0.  1.  4.  9.]\n",
      " [16. 25. 36. 49. 64.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"x:\", x)\n",
    "print(\"y:\", y)\n",
    "\n",
    "result = squared_diff(x,y)\n",
    "\n",
    "print(\"result :\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "79d54e6b"
   },
   "outputs": [],
   "source": [
    "# Example taken from docs\n",
    "\n",
    "x = cp.arange(10, dtype=np.float32).reshape(2, 5)\n",
    "y = cp.arange(10, dtype=np.float32).reshape(2, 5)\n",
    "\n",
    "add_reverse = cp.ElementwiseKernel(\n",
    "    'T x, raw T y', \n",
    "    'T z',\n",
    "    '''\n",
    "    z = x + y[_ind.size() - i - 1];\n",
    "    ''',\n",
    "    'add_reverse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9cf5c072",
    "outputId": "0d425e2d-42cc-401e-f762-189b8774332d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [[0. 1. 2. 3. 4.]\n",
      " [5. 6. 7. 8. 9.]]\n",
      "y: [[0. 1. 2. 3. 4.]\n",
      " [5. 6. 7. 8. 9.]]\n",
      "result : [[9. 9. 9. 9. 9.]\n",
      " [9. 9. 9. 9. 9.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"x:\", x)\n",
    "print(\"y:\", y)\n",
    "\n",
    "result = add_reverse(x,y)\n",
    "\n",
    "print(\"result :\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9acf9153-c19d-4cd4-a010-764a49254fb2"
   },
   "source": [
    "You can find even more complex custom CUDA kernel. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b710dd61-63dd-435c-a4c1-e5d765b9b1ed"
   },
   "source": [
    "<a name=\"CuDF\"></a>\n",
    "## CuDF and CuML\n",
    "\n",
    "CuDF is develeopped by rapidsai (https://rapids.ai/) and like CuPY the goal is to have the features of pandas using GPUs. CuML is also develeopped by rapidsai (https://rapids.ai/) and this time the library we want to apply GPUs is Scikit-learn. Installing them on google collab is a bit complex so we will directly use their google collab cells:https://colab.research.google.com/drive/1rY7Ln6rEE1pOlfSHCYOVaqt8OvDO35J0#forceEdit=true&sandboxMode=true&scrollTo=JI7UTXbhaBon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fd6fd872"
   },
   "source": [
    "<a name=\"Numba\"></a>\n",
    "## Numba\n",
    "\n",
    "Numba is a just-in-time (https://en.wikipedia.org/wiki/Just-in-time_compilation), type-specializing, function compiler for accelerating numerically-focused Python. That's a long list, so let's break down those terms: \n",
    "\n",
    "- function compiler: Numba compiles Python functions, not entire applications, and not parts of functions. Numba does not replace your Python interpreter, but is just another Python module that can turn a function into a (usually) faster function.\n",
    "- type-specializing: Numba speeds up your function by generating a specialized implementation for the specific data types you are using. Python functions are designed to operate on generic data types, which makes them very flexible, but also very slow. In practice, you only will call a function with a small number of argument types, so Numba will generate a fast implementation for each set of types.\n",
    "- just-in-time: Numba translates functions when they are first called. This ensures the compiler knows what argument types you will be using. This also allows Numba to be used interactively in a Jupyter notebook just as easily as a traditional application\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "sa6sfAxa3G2z"
   },
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "import numpy as np\n",
    "\n",
    "x = np.random.rand(20000, 1000).astype('f')\n",
    "y = np.random.rand(20000, 1).astype('f')\n",
    "\n",
    "@jit\n",
    "def ols(x, y):\n",
    "    beta = np.dot(np.linalg.inv(np.dot(x.T,x)),np.dot(x.T,y))\n",
    "    return beta[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bk_N_hLM59ak",
    "outputId": "28c843e8-9b4e-471d-9f7d-40b81f243972"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 5: 682 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit ols(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w4BjC6Yh7WRN",
    "outputId": "2ed9cfd7-020f-4ff2-9a20-454686082a6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 5: 468 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit ols.py_func(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wmhzuu_W7cPZ"
   },
   "source": [
    "As a reminder, numpy is written in C which means its already extremly fast. Read more on numpy and numba here https://numba.pydata.org/numba-doc/dev/reference/numpysupported.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0daf7f25"
   },
   "source": [
    "Numba can also be used to create new numpy universal function.\n",
    "https://numba.pydata.org/numba-doc/dev/user/vectorize.html\n",
    "\n",
    "Numba’s vectorize allows Python functions taking scalar input arguments to be used as NumPy ufuncs. Creating a traditional NumPy ufunc is not the most straightforward process and involves writing some C code. Numba makes this easy. Using the vectorize() decorator, Numba can compile a pure Python function into a ufunc that operates over NumPy arrays as fast as traditional ufuncs written in C.\n",
    "\n",
    "Using vectorize(), you write your function as operating over input scalars, rather than arrays. Numba will generate the surrounding loop (or kernel) allowing efficient iteration over the actual inputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cee3a3d3"
   },
   "outputs": [],
   "source": [
    "%%timeit \n",
    "\n",
    "from numba import vectorize, float64\n",
    "import numpy as np\n",
    "\n",
    "@vectorize([float64(float64, float64)])\n",
    "def f(x, y):\n",
    "    x - y\n",
    "    return x + y\n",
    "N = 100000000\n",
    "A = np.array(np.random.sample(N), dtype=np.float64)\n",
    "B = np.array(np.random.sample(N), dtype=np.float64)\n",
    "result = f(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "626d6a6d"
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "from numba import vectorize, float64\n",
    "import numpy as np\n",
    "\n",
    "@vectorize([float64(float64, float64)], target = \"parallel\")\n",
    "def f(x, y):\n",
    "    x - y\n",
    "    return x + y\n",
    "\n",
    "N = 100000000\n",
    "A = np.array(np.random.sample(N), dtype=np.float64)\n",
    "B = np.array(np.random.sample(N), dtype=np.float64)\n",
    "f(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2df1c9a7-445b-406d-bb9b-f304965a6a42"
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def f(x, y):\n",
    "    x - y\n",
    "    return x + y\n",
    "\n",
    "N = 100000000\n",
    "A = np.array(np.random.sample(N), dtype=np.float64)\n",
    "B = np.array(np.random.sample(N), dtype=np.float64)\n",
    "f(A,B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qauLRpb-8Dqy"
   },
   "source": [
    "You can do other things than using numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "f1819171"
   },
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "import math\n",
    "\n",
    "@jit\n",
    "def hypot(x, y):\n",
    "    # Implementation from https://en.wikipedia.org/wiki/Hypot\n",
    "    x = abs(x)\n",
    "    y = abs(y)\n",
    "    t = min(x, y)\n",
    "    x = max(x, y)\n",
    "    t = t / x\n",
    "    return x * math.sqrt(1+t*t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "58132e26"
   },
   "source": [
    "The first time we call hypot, the compiler is triggered and compiles a machine code implementation for float inputs. Numba also saves the original Python implementation of the function in the .py_func attribute, so we can call the original Python code to make sure we get the same answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b6c39650",
    "outputId": "1524b05f-bb9a-4e87-c824-7c4effbfdf98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 317085.61 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1000000 loops, best of 5: 240 ns per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit hypot(10,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a0c453fc",
    "outputId": "62cecaf6-26e2-472e-bd9d-13bbe3b24e12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 14.34 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1000000 loops, best of 5: 887 ns per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit hypot.py_func(10,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "605c5a55"
   },
   "source": [
    "How does numba works ? From https://towardsdatascience.com/speed-up-your-algorithms-part-2-numba-293e554c5cc1\n",
    "\n",
    "![numba](img/numba.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d99ff0c5"
   },
   "source": [
    "Numba also supports GPU programming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "983c0a19"
   },
   "outputs": [],
   "source": [
    "import numba\n",
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "def642e8"
   },
   "outputs": [],
   "source": [
    "# list of devices\n",
    "print(cuda.gpus)\n",
    "# Select your device\n",
    "numba.cuda.select_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "6f13fc08-727b-4e77-a3e9-e4a0d810fcd6"
   },
   "outputs": [],
   "source": [
    "from numba import vectorize\n",
    "import numpy as np\n",
    "\n",
    "@vectorize(['int64(int64, int64)'], target='cuda')\n",
    "def add_ufunc(x, y):\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7f2b196a-22d8-4c62-b6c2-5a7b4f1315cb",
    "outputId": "0becfb7a-d24a-4932-bdd1-5df928557032"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a+b:\n",
      " [11 22 33 44]\n",
      "\n",
      "\n",
      "\n",
      "b_col + c:\n",
      " [[10 11 12 13]\n",
      " [24 25 26 27]\n",
      " [38 39 40 41]\n",
      " [52 53 54 55]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1, 2, 3, 4])\n",
    "b = np.array([10, 20, 30, 40])\n",
    "b_col = b.reshape(4,1)\n",
    "c = np.arange(4*4).reshape((4,4))\n",
    "\n",
    "print('a+b:\\n', add_ufunc(a, b))\n",
    "print('\\n\\n')\n",
    "print('b_col + c:\\n', add_ufunc(b_col, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7d8b8664-cd40-4880-a18d-eb842dde0a18",
    "outputId": "e66b20f2-8f3b-4b3f-f7c1-7efae16eb359"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 113.47 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1000000 loops, best of 5: 1.17 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit np.add(b_col, c)   # NumPy on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fec616ca-8884-402e-8a08-b62c4de80a00",
    "outputId": "8907f1e4-8f72-4f08-ce3b-8b08265e9579"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 5: 1.69 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit add_ufunc(b_col, c) # Numba on GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6ec62c8"
   },
   "source": [
    "Why is the GPU slower ?\n",
    "* Our inputs are too small: the GPU achieves performance through parallelism, operating on thousands of values at once. Our test inputs have only 4 and 16 integers, respectively. We need a much larger array to even keep the GPU busy.\n",
    "* Our calculation is too simple: Sending a calculation to the GPU involves quite a bit of overhead compared to calling a function on the CPU. If our calculation does not involve enough math operations (often called \"arithmetic intensity\"), then the GPU will spend most of its time waiting for data to move around.\n",
    "* We copy the data to and from the GPU: While including the copy time can be realistic for a single function, often we want to run several GPU operations in sequence. In those cases, it makes sense to send data to the GPU and keep it there until all of our processing is complete.\n",
    "* Our data types are larger than necessary: Our example uses int64 when we probably don't need it. Scalar code using data types that are 32 and 64-bit run basically the same speed on the CPU, but 64-bit data types have a significant performance cost on the GPU. Basic arithmetic on 64-bit floats can be anywhere from 2x (Pascal-architecture Tesla) to 24x (Maxwell-architecture GeForce) slower than 32-bit floats. NumPy defaults to 64-bit data types when creating arrays, so it is important to set the dtype attribute or use the ndarray.astype() method to pick 32-bit types when you need them.\n",
    "\n",
    "Let's see a bigger example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "16eec456"
   },
   "outputs": [],
   "source": [
    "from numba import vectorize\n",
    "import numpy as np\n",
    "import math  # Note that for the CUDA target, we need to use the scalar functions from the math module, not NumPy\n",
    "\n",
    "@vectorize(['float32(float32, float32, float32)'], target='cuda')\n",
    "def gaussian_pdf(x, mean, sigma):\n",
    "    '''Compute the value of a Gaussian probability density function at x with given mean and sigma.'''\n",
    "    return math.exp(-0.5 * ((x - mean) / sigma)**2) / (sigma * np.float32((2*math.pi)**0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "697e206a"
   },
   "outputs": [],
   "source": [
    "x = np.random.uniform(-3, 3, size=1000000).astype(np.float32)\n",
    "mean = np.float32(0.0)\n",
    "sigma = np.float32(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ee5b1cc",
    "outputId": "611301d3-7ec5-495a-fec8-65bb0ee097af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 79.18 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1 loop, best of 5: 4.36 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit gaussian_pdf(x, mean, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e2026410",
    "outputId": "ca3636ce-cb73-4550-9fbc-57c5c3718621"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 5: 63.7 ms per loop\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats # for definition of gaussian distribution\n",
    "norm_pdf = scipy.stats.norm\n",
    "%timeit norm_pdf.pdf(x, loc=mean, scale=sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "049f9ca4-5057-4554-b033-7a077f51993b"
   },
   "source": [
    "Of course not everything can be vectorized so you'll need to create your own cuda kernel. We won't go into the details here but if you want to learn more on numba, please look at the following links:\n",
    "\n",
    "- https://www.youtube.com/watch?v=9bBsvpg-Xlk\n",
    "- https://www.youtube.com/watch?v=CQDsT81GyS8&t\n",
    "- https://colab.research.google.com/drive/15IDLiUMRJbKqZUZPccyigudINCD5uZ71?usp=sharing\n",
    "- https://numba.pydata.org/numba-doc/latest/cuda/kernels.html\n",
    "- https://docs.nvidia.com/cuda/cuda-c-programming-guide/\n",
    "- https://stackoverflow.com/questions/4391162/cuda-determining-threads-per-block-blocks-per-grid\n",
    "- https://en.wikipedia.org/wiki/CUDA\n",
    "- https://nyu-cds.github.io/python-numba/05-cuda/\n",
    "- https://numba.pydata.org/numba-doc/latest/cuda/ufunc.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ea3c80c"
   },
   "source": [
    "## Numba limitations\n",
    "\n",
    "Numba accelerates your code. So why should'nt we use it for everything if it's has simple as putting a decorator in front of a function ?\n",
    "\n",
    "Well it's not that simple.\n",
    "\n",
    "Numba is numerically-focused: Currently, Numba is focused on numerical data types, like int, float, and complex. There is very limited string processing support, and many string use cases are not going to work well on the GPU. To get best results with Numba, you will likely be using NumPy arrays. When you run a function that uses string or dict, python ignores the jit decorator and run the function as normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "71c499c7"
   },
   "outputs": [],
   "source": [
    "@jit()\n",
    "def cannot_compile(x):\n",
    "    return x['key']\n",
    "\n",
    "cannot_compile(dict(key='hey heres your value'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3750e33b"
   },
   "source": [
    "To avoid this type of behavior (we want an error message and not just a warning) we add the argument nopython = True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e514da7c"
   },
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def cannot_compile(x):\n",
    "    return x['key']\n",
    "\n",
    "cannot_compile(dict(key='hey heres your value'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6765437b"
   },
   "source": [
    "<a name=\"TODO\"></a>\n",
    "## TODO\n",
    "\n",
    "code review: \n",
    "- https://www.programcreek.com/python/example/111769/cupy.ElementwiseKernel"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Chapter3.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
